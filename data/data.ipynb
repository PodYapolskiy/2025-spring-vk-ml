{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from pydantic import BaseModel\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 10)  # (w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class Row(BaseModel):  # , arbitrary_types_allowed=True):\n",
    "    #\n",
    "    image_path: str  # PIL.Image.Image\n",
    "\n",
    "    # ...\n",
    "    industry_name: str\n",
    "    company_name: str\n",
    "\n",
    "    # bounding box (xmin, ymin, xmax, ymax)\n",
    "    bbox: tuple[int, int, int, int]\n",
    "\n",
    "    # @property\n",
    "    # def image(self) -> np.ndarray:\n",
    "    #     img = Image.open(self.image_path)\n",
    "    #     return np.array(img.convert(\"RGB\"))\n",
    "\n",
    "\n",
    "rows = []\n",
    "data_path = Path(\"../data\")\n",
    "dataset_name = \"LogoDet-3K\"\n",
    "dataset_path = data_path / dataset_name\n",
    "\n",
    "for industry_path in dataset_path.iterdir():\n",
    "    if not industry_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    for company_path in industry_path.iterdir():\n",
    "        if not company_path.is_dir():\n",
    "            continue\n",
    "\n",
    "        for file_path in company_path.iterdir():\n",
    "            if not file_path.is_file():\n",
    "                continue\n",
    "\n",
    "            if file_path.suffix == \".xml\":\n",
    "                # make sure for each xml file there exist corresponding jpg\n",
    "                image_path = file_path.with_suffix(\".jpg\")\n",
    "                assert image_path.exists()\n",
    "\n",
    "                # parse xml\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                xmin = int(root[-1][-1][0].text)\n",
    "                ymin = int(root[-1][-1][1].text)\n",
    "                xmax = int(root[-1][-1][2].text)\n",
    "                ymax = int(root[-1][-1][3].text)\n",
    "\n",
    "                row = Row(\n",
    "                    # image related\n",
    "                    image_path=str(image_path.relative_to(data_path)),\n",
    "                    # meta\n",
    "                    industry_name=industry_path.name,\n",
    "                    company_name=company_path.name,\n",
    "                    # bounding box\n",
    "                    bbox=(xmin, ymin, xmax, ymax),\n",
    "                )\n",
    "                rows.append(row.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solan/repos/contests/2025-spring-vk-ml/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Casting to class labels: 100%|██████████| 158654/158654 [00:00<00:00, 471789.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.Dataset.from_list(rows).cast_column(\"image_path\", datasets.Image())\n",
    "dataset = dataset.class_encode_column(\"company_name\")  # to be able to split\n",
    "dataset = dataset.train_test_split(0.2, seed=42, stratify_by_column=\"company_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image_path', 'industry_name', 'company_name', 'bbox'],\n",
       "        num_rows: 126923\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image_path', 'industry_name', 'company_name', 'bbox'],\n",
       "        num_rows: 31731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=521x382>,\n",
       " 'industry_name': 'Others',\n",
       " 'company_name': 2063,\n",
       " 'bbox': [282, 146, 512, 258]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = datasets.load_from_disk( data_dir=data_path)\n",
    "\n",
    "dataset['train'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 21154/21154 [00:08<00:00, 2525.43 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 212/212 [00:00<00:00, 228.37ba/s]\n",
      "Map: 100%|██████████| 21154/21154 [00:09<00:00, 2176.94 examples/s].92s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 212/212 [00:01<00:00, 187.76ba/s]\n",
      "Map: 100%|██████████| 21154/21154 [00:08<00:00, 2353.18 examples/s].36s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 212/212 [00:00<00:00, 320.48ba/s]\n",
      "Map: 100%|██████████| 21154/21154 [00:08<00:00, 2639.89 examples/s].42s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 212/212 [00:00<00:00, 300.00ba/s]\n",
      "Map: 100%|██████████| 21154/21154 [00:07<00:00, 2652.02 examples/s].67s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 212/212 [00:00<00:00, 216.66ba/s]\n",
      "Map: 100%|██████████| 21153/21153 [00:08<00:00, 2638.08 examples/s].12s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 212/212 [00:00<00:00, 266.92ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 6/6 [02:21<00:00, 23.56s/it]\n",
      "Map: 100%|██████████| 15866/15866 [00:06<00:00, 2602.14 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 159/159 [00:00<00:00, 259.16ba/s]\n",
      "Map: 100%|██████████| 15865/15865 [00:05<00:00, 2648.12 examples/s].21s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 159/159 [00:00<00:00, 270.71ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:35<00:00, 17.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/PodYapolsky/LogoDet-3K/commit/312539077a17bd6b56b871ca032e84512f4a6cdd', commit_message='Upload dataset', commit_description='', oid='312539077a17bd6b56b871ca032e84512f4a6cdd', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/PodYapolsky/LogoDet-3K', endpoint='https://huggingface.co', repo_type='dataset', repo_id='PodYapolsky/LogoDet-3K'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\n",
    "    repo_id=\"PodYapolsky/LogoDet-3K\",\n",
    "    commit_message=\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
